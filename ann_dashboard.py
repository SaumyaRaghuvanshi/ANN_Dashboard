# -*- coding: utf-8 -*-
"""ANN_Dashboard.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ncYmQrkWcfRtpMlY2OwC389R-vJ-4jta
"""

import streamlit as st
import pandas as pd
import numpy as np
import gdown
import os
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, BatchNormalization
from tensorflow.keras.optimizers import Adam, SGD, RMSprop
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

# Load dataset
st.title('üìä Sales Prediction Dashboard - ANN Model')

# Upload dataset
TRAIN_FILE_ID = "1Isp2tA7MnXcNu9le5Lu7wwJNP7Kt67Ky"
TRAIN_PATH = "train.csv"

# Download the datasets automatically if not present
if not os.path.exists(TRAIN_PATH):
    gdown.download(f"https://drive.google.com/uc?id={TRAIN_FILE_ID}", TRAIN_PATH, quiet=False)


df = pd.read_csv(TRAIN_PATH)
st.write("### Raw Dataset Preview:", df.head())

    # Data Cleaning
    df.drop(columns=['Customers', 'PromoInterval'], errors='ignore', inplace=True)
    df['Date'] = pd.to_datetime(df['Date'])
    df['Year'] = df['Date'].dt.year
    df['Month'] = df['Date'].dt.month
    df['Day'] = df['Date'].dt.day
    df['WeekOfYear'] = df['Date'].dt.isocalendar().week

    df.fillna(df.median(), inplace=True)

    categorical_cols = ['StoreType', 'Assortment', 'StateHoliday']
    df = pd.get_dummies(df, columns=categorical_cols, drop_first=True)

    # Normalize numerical features
    num_cols = ['CompetitionDistance', 'CompetitionOpenSinceMonth', 'CompetitionOpenSinceYear',
                'Promo2SinceWeek', 'Promo2SinceYear', 'Year', 'Month', 'Day', 'WeekOfYear']
    scaler = StandardScaler()
    df[num_cols] = scaler.fit_transform(df[num_cols])

    st.write("### Cleaned Dataset Preview:", df.head())

    # Sidebar - Hyperparameters
    st.sidebar.header("Model Hyperparameters")
    num_layers = st.sidebar.slider("Hidden Layers", 1, 5, 3)
    neurons_per_layer = st.sidebar.slider("Neurons per Layer", 32, 256, 128)
    activation = st.sidebar.selectbox("Activation", ['relu', 'tanh', 'sigmoid'])
    dropout_rate = st.sidebar.slider("Dropout Rate", 0.0, 0.5, 0.3)
    optimizer_choice = st.sidebar.selectbox("Optimizer", ['adam', 'sgd', 'rmsprop'])
    learning_rate = st.sidebar.slider("Learning Rate", 0.0001, 0.01, 0.001)
    epochs = st.sidebar.slider("Epochs", 10, 100, 50)

    # Train-Test Split
    X = df.drop(columns=['Sales', 'Date'])
    y = df['Sales']
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    if st.button("üöÄ Train Model"):
        st.write("### Model Training in Progress...")

        # Build Model
        model = Sequential()
        model.add(Dense(neurons_per_layer, activation=activation, input_shape=(X_train.shape[1],)))
        model.add(BatchNormalization())
        model.add(Dropout(dropout_rate))

        for _ in range(num_layers - 1):
            model.add(Dense(neurons_per_layer, activation=activation))
            model.add(BatchNormalization())
            model.add(Dropout(dropout_rate))

        model.add(Dense(1, activation='linear'))

        optimizer_dict = {'adam': Adam(learning_rate), 'sgd': SGD(learning_rate), 'rmsprop': RMSprop(learning_rate)}
        model.compile(loss='mse', optimizer=optimizer_dict[optimizer_choice], metrics=['mae'])

        history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=epochs, batch_size=64, verbose=1)

        st.success("üéâ Model Training Complete!")

        # Plot Performance Metrics
        fig, ax = plt.subplots(1, 2, figsize=(12, 5))
        ax[0].plot(history.history['mae'], label='Train MAE', color='blue')
        ax[0].plot(history.history['val_mae'], label='Val MAE', color='orange')
        ax[0].set_title('üìà Mean Absolute Error')
        ax[0].set_xlabel('Epochs')
        ax[0].set_ylabel('MAE')
        ax[0].legend()

        ax[1].plot(history.history['loss'], label='Train Loss', color='blue')
        ax[1].plot(history.history['val_loss'], label='Val Loss', color='orange')
        ax[1].set_title('üìâ Model Loss')
        ax[1].set_xlabel('Epochs')
        ax[1].set_ylabel('Loss')
        ax[1].legend()

        st.pyplot(fig)

        # Model Predictions
        y_pred = model.predict(X_test)
        mse = mean_squared_error(y_test, y_pred)
        rmse = np.sqrt(mse)
        mae = mean_absolute_error(y_test, y_pred)
        r2 = r2_score(y_test, y_pred)

        st.write("### ‚úÖ Model Evaluation")
        st.write(f"üìä **MSE:** {mse:.4f}")
        st.write(f"üìâ **RMSE:** {rmse:.4f}")
        st.write(f"üìè **MAE:** {mae:.4f}")
        st.write(f"üî¢ **R¬≤ Score:** {r2:.4f}")

        # Actual vs Predicted Sales Plot
        fig, ax = plt.subplots(figsize=(12, 6))
        ax.scatter(y_test, y_pred, alpha=0.5, label='Predicted vs Actual', color='royalblue')
        ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', label='Perfect Prediction')
        ax.set_xlabel('Actual Sales')
        ax.set_ylabel('Predicted Sales')
        ax.set_title('üìä Actual vs Predicted Sales')
        ax.legend()
        st.pyplot(fig)

        # Residual Plot
        residuals = y_test - y_pred.flatten()
        fig, ax = plt.subplots(figsize=(12, 6))
        ax.scatter(y_pred, residuals, alpha=0.5, color='purple')
        ax.axhline(0, color='red', linestyle='--')
        ax.set_xlabel('Predicted Sales')
        ax.set_ylabel('Residuals')
        ax.set_title('üìâ Residual Plot')
        st.pyplot(fig)