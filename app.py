# -*- coding: utf-8 -*-
"""app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-v3SIXtwpl4sH_M4O6IOgSo4SVKL5yty
"""

import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, BatchNormalization
from tensorflow.keras.optimizers import Adam, SGD, RMSprop
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

# Streamlit UI
st.title('üìä Rossmann Sales Prediction Dashboard - Deep Learning')

# Upload dataset
uploaded_train = st.file_uploader("üìÇ Upload Train CSV", type=['csv'])
uploaded_store = st.file_uploader("üìÇ Upload Store CSV", type=['csv'])

if uploaded_train and uploaded_store:
    # Load datasets
    train_df = pd.read_csv(uploaded_train)
    store_df = pd.read_csv(uploaded_store)

    st.write("### üîç Train Dataset Preview:", train_df.head())
    st.write("### üîç Store Dataset Preview:", store_df.head())

    # üî• Merge the datasets on Store ID
    df = train_df.merge(store_df, how="left", on="Store")

    # ‚úÖ Drop unnecessary columns
    columns_to_drop = ['Customers', 'PromoInterval']  # 'Customers' is not needed for predictions
    df.drop(columns=columns_to_drop, inplace=True)

    # ‚úÖ Convert date column to datetime format
    df['Date'] = pd.to_datetime(df['Date'])

    # ‚úÖ Extract date features
    df['Year'] = df['Date'].dt.year
    df['Month'] = df['Date'].dt.month
    df['Day'] = df['Date'].dt.day
    df['WeekOfYear'] = df['Date'].dt.isocalendar().week

    # ‚úÖ Handle missing values
    df['CompetitionDistance'].fillna(df['CompetitionDistance'].median(), inplace=True)
    df['CompetitionOpenSinceMonth'].fillna(0, inplace=True)
    df['CompetitionOpenSinceYear'].fillna(0, inplace=True)
    df['Promo2SinceWeek'].fillna(0, inplace=True)
    df['Promo2SinceYear'].fillna(0, inplace=True)

    # ‚úÖ Encoding categorical variables
    cat_cols = ['StoreType', 'Assortment', 'StateHoliday']
    df = pd.get_dummies(df, columns=cat_cols, drop_first=True)

    # ‚úÖ Scaling numerical features
    num_cols = ['CompetitionDistance', 'CompetitionOpenSinceMonth', 'CompetitionOpenSinceYear',
                'Promo2SinceWeek', 'Promo2SinceYear', 'Year', 'Month', 'Day', 'WeekOfYear']

    scaler = StandardScaler()
    df[num_cols] = scaler.fit_transform(df[num_cols])

    # ‚úÖ Train-Test Split
    X = df.drop(columns=['Sales', 'Date'])
    y = df['Sales']

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    st.write("‚úÖ Data Preprocessing Complete!")

    # Sidebar for Hyperparameter Selection
    st.sidebar.header("Model Hyperparameters")

    num_layers = st.sidebar.slider("Number of Hidden Layers", 1, 5, 3)
    neurons_per_layer = st.sidebar.slider("Neurons per Layer", 32, 256, 128)
    activation = st.sidebar.selectbox("Activation Function", ['relu', 'tanh', 'sigmoid'])
    dropout_rate = st.sidebar.slider("Dropout Rate", 0.0, 0.5, 0.3)
    optimizer = st.sidebar.selectbox("Optimizer", ['adam', 'sgd', 'rmsprop'])
    learning_rate = st.sidebar.slider("Learning Rate", 0.0001, 0.01, 0.001)
    epochs = st.sidebar.slider("Number of Epochs", 10, 100, 50)

    # Model Training Button
    if st.button("üöÄ Train Model"):
        with st.spinner('Training ANN Model... Please wait!'):

            # Build ANN Model
            model = Sequential()

            # Input Layer
            model.add(Dense(neurons_per_layer, activation=activation, input_shape=(X_train.shape[1],)))
            model.add(BatchNormalization())
            model.add(Dropout(dropout_rate))

            # Hidden Layers
            for _ in range(num_layers - 1):
                model.add(Dense(neurons_per_layer, activation=activation))
                model.add(BatchNormalization())
                model.add(Dropout(dropout_rate))

            # Output Layer
            model.add(Dense(1, activation='linear'))

            # Compile Model
            optimizer_dict = {
                "adam": Adam(learning_rate=learning_rate),
                "sgd": SGD(learning_rate=learning_rate),
                "rmsprop": RMSprop(learning_rate=learning_rate)
            }

            model.compile(
                loss='mse',
                optimizer=optimizer_dict[optimizer],
                metrics=['mae']
            )

            # Train the model
            history = model.fit(
                X_train, y_train,
                validation_data=(X_test, y_test),
                epochs=epochs,
                batch_size=64,
                verbose=1
            )

            st.success("üéâ Model Training Completed!")

            # Plot Loss
            fig, ax = plt.subplots()
            ax.plot(history.history['loss'], label='Training Loss')
            ax.plot(history.history['val_loss'], label='Validation Loss')
            ax.set_xlabel("Epochs")
            ax.set_ylabel("Loss")
            ax.legend()
            st.pyplot(fig)

            # Plot MAE
            fig, ax = plt.subplots()
            ax.plot(history.history['mae'], label='Training MAE')
            ax.plot(history.history['val_mae'], label='Validation MAE')
            ax.set_xlabel("Epochs")
            ax.set_ylabel("MAE")
            ax.legend()
            st.pyplot(fig)

            # Final Evaluation
            y_pred = model.predict(X_test)

            mse = mean_squared_error(y_test, y_pred)
            mae = mean_absolute_error(y_test, y_pred)
            r2 = r2_score(y_test, y_pred)

            st.write("### ‚úÖ Model Evaluation")
            st.write(f"üìà MSE: {mse:.4f}")
            st.write(f"üìâ MAE: {mae:.4f}")
            st.write(f"üî¢ R¬≤ Score: {r2:.4f}")

            # Model Summary
            st.write("### üî• Model Summary")
            for layer in model.layers:
                st.write(f"Layer: {layer.name}, Output Shape: {layer.output_shape}, Parameters: {layer.count_params()}")